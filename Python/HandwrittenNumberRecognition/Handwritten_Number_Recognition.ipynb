{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handwritten number recognition using data from MNIST - Using deep-learning\n",
    "build a neural network that recognizes handwritten numbers 0-9\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "import tflearn.datasets.mnist as mnist  #MNIST data import\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the training and test data\n",
    "trainX, trainY, testX, testY = mnist.load_data(one_hot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting routine\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Function for displaying a training image by it's index in the MNIST set\n",
    "def display_digit(index):\n",
    "    label = trainY[index].argmax(axis=0)\n",
    "    # Reshape 784 array into 28x28 image\n",
    "    image = trainX[index].reshape([28,28])\n",
    "    plt.title('Training data, index: %d,  Label: %d' % (index, label))\n",
    "    plt.imshow(image, cmap='gray_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of trainX matrix: (55000, 784)\n",
      "# rows of trainX matrix: 55000\n",
      "# cols of trainX matrix: 784 \n",
      "\n",
      "shape of trainY matrix: (55000, 10) \n",
      "\n",
      "trainY matrix for input image number 2 is: [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "corresponding number for input image number 2 is: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16306a4e048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# getting some intuitiou on the data and dimensions\n",
    "index = 2   #choosing just one picture to show\n",
    "\n",
    "print(\"shape of trainX matrix:\", trainX.shape)\n",
    "print(\"# rows of trainX matrix:\", trainX.shape[0]) #55000 cases\n",
    "print(\"# cols of trainX matrix:\", trainX.shape[1],'\\n') #flattened image pixels 28*28 = 784\n",
    "print(\"shape of trainY matrix:\", trainY.shape,'\\n') #array of size 10, which is unity at the number that image represents\n",
    "print(\"trainY matrix for input image number %d\" % index ,\"is:\" , trainY[index,:])\n",
    "print(\"corresponding number for input image number %d\" % index, \"is:\", trainY[index].argmax(axis=0)) # get the indice of the maximum element in the array i.e. the number represented by pic\n",
    "\n",
    "# Display the training image represented by index specified above\n",
    "display_digit(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "def build_model():\n",
    "    # Resetting all parameters and variables\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Inputs\n",
    "    net = tflearn.input_data([None, trainX.shape[1]])\n",
    "\n",
    "    # Hidden layer(s)\n",
    "    net = tflearn.fully_connected(net, 128, activation='ReLU')\n",
    "    net = tflearn.fully_connected(net, 32, activation='ReLU')\n",
    "    \n",
    "    # Output layer and training model\n",
    "    net = tflearn.fully_connected(net, 10, activation='softmax')\n",
    "    net = tflearn.regression(net, optimizer='sgd', learning_rate=0.01, loss='categorical_crossentropy')\n",
    "    # DNN: Deep Neural Network\n",
    "    model = tflearn.DNN(net)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 49499  | total loss: \u001b[1m\u001b[32m0.05574\u001b[0m\u001b[0m | time: 1.401s\n",
      "| SGD | epoch: 100 | loss: 0.05574 - acc: 0.9875 -- iter: 49400/49500\n",
      "Training Step: 49500  | total loss: \u001b[1m\u001b[32m0.05684\u001b[0m\u001b[0m | time: 2.410s\n",
      "| SGD | epoch: 100 | loss: 0.05684 - acc: 0.9867 | val_loss: 0.10038 - val_acc: 0.9715 -- iter: 49500/49500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "model = build_model()\n",
    "\n",
    "# Training the model with batch size and # epochs of both 100 \n",
    "# 0.1 is given as split factor to be used on the training data to set some images for evaluation in a validation set\n",
    "model.fit(trainX, trainY, validation_set=0.1, show_metric=True, batch_size=100, n_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.77493836e-07   8.38764265e-07   5.49937649e-05   5.40577399e-04\n",
      "    1.02067119e-10   6.38859945e-07   8.10616927e-13   9.99240875e-01\n",
      "    3.22950218e-05   1.29231339e-04]\n",
      " [  4.96269230e-08   8.93276665e-05   9.97583389e-01   1.61491931e-04\n",
      "    3.65933205e-18   7.72375515e-08   6.33526770e-06   2.34044663e-13\n",
      "    2.15930468e-03   1.38187408e-13]]\n",
      "Test accuracy:  0.9719\n"
     ]
    }
   ],
   "source": [
    "# Comparing the labels that the model predicts with the actual labels\n",
    "# testX is a test sample of dim 10000*784\n",
    "print (np.array(model.predict(testX))[0:2]) #probabilty of each digit that can be assigned for the first two test images (10*2 dim)\n",
    "\n",
    "# Find the indices of the most confident prediction for each item, this tells the predicted digit for that sample\n",
    "predictions = np.array(model.predict(testX)).argmax(axis=1)\n",
    "\n",
    "# Calculate the accuracy as the percentage of times the predicted labels matched the actual labels\n",
    "actual = testY.argmax(axis=1)\n",
    "test_accuracy = np.mean(predictions == actual, axis=0)\n",
    "\n",
    "# the test_accuracy result\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
