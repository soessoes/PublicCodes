{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "import matplotlib as plt\n",
    "import sys\n",
    "import os\n",
    "import fnmatch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lables of the ADNI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = pd.read_csv(\"./Data/ADNI_Lables_Total.csv\")               # when the lables of the ADNI dataset are saved in csv file in folder named \"Data\"\n",
    "dict_imageStatus = dict(zip(alldata.Subject, alldata.Status))       # Saving the dataset in a dictionray with key: patients' IDs and value: patients' Alzheimer status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADNI MRI pictures processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images processed:  10 , No. of batches saved:  1\n"
     ]
    }
   ],
   "source": [
    "rootPath = './Data'              # when the MRI images are saved in a folder named \"Data\"\n",
    "pattern = '*.nii'\n",
    "                                       \n",
    "[processedImgNo, counter] = [1, 1]    \n",
    "[batchNo, batchSize] = [1, 10]\n",
    "\n",
    "X = Y = np.array([])                                        # X: matrix of features (number of samples (m) by number of features (n = 256 * 256 * 170))\n",
    "                                                            # Y: matrix of lables (number of samples (m) by 1)\n",
    "# XY_Values: folder for saving X matrix and Y matrix\n",
    "if not os.path.exists('XY_Values'):\n",
    "    os.makedirs('XY_Values')\n",
    "    \n",
    "for root, dirs, files in os.walk(rootPath):\n",
    "    for filename in fnmatch.filter(files, pattern):\n",
    "        dict_imageData = dict()  # a dicionary from subject_ID to pixels of it's MRI picture (picture: a 3rd order tensor)\n",
    "        dataFiles = [] \n",
    "        dataFiles = (os.path.join(root, filename)) \n",
    "        key = str(dataFiles.split('\\\\')[1])                 # subject_ID\n",
    "        img = image.load_img(dataFiles) \n",
    "        val = img.get_data()[:, :, :]                         # getting the images data\n",
    "        \n",
    "        # padding val matrix with zeros to enlarge them upto the size 256*256*170\n",
    "        [xshape, yshape, zshape] = [val.shape[0], val.shape[1], val.shape[2]]\n",
    "        [xpad, ypad, zpad] = [int((256-xshape)*0.5), int((256-yshape)*0.5), int((170-zshape)*0.5)]\n",
    "        valPadded = np.pad(val, ((xpad, xpad), (ypad, ypad), (zpad, zpad)), 'constant')\n",
    "        \n",
    "        val = np.reshape(valPadded, [-1])                   # flattening the images data into a row vector\n",
    "        dict_imageData [key] = (np.array(val))\n",
    "                            \n",
    "        for key, value in dict_imageData.items():           # looping through dictionary of image data\n",
    "            if key in dict_imageStatus.keys():\n",
    "                if X.size != 0:\n",
    "                        X = np.vstack([X, (value)])\n",
    "                        Y = np.vstack([Y, dict_imageStatus[key]])\n",
    "                else:\n",
    "                        X = (value)\n",
    "                        Y = dict_imageStatus[key]\n",
    "                        \n",
    "                if counter % batchSize == 0:\n",
    "                    counter = 1\n",
    "                    assert(X.shape[0] == Y.shape[0])\n",
    "                    assert(X.shape[1] == 256 * 256 * 170 )  \n",
    "                    np.save(os.path.join('XY_Values', 'XValues' + str(batchNo) + '.npy'), X)\n",
    "                    np.save(os.path.join('XY_Values', 'YValues' + str(batchNo) + '.npy'), Y)\n",
    "                    print('No. of images processed: ', processedImgNo , ', No. of batches saved: ', batchNo)\n",
    "                    batchNo = batchNo + 1\n",
    "                    X = np.array([]) \n",
    "                    Y = np.array([]) \n",
    "                else: \n",
    "                    counter = counter + 1\n",
    "                processedImgNo = processedImgNo + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
