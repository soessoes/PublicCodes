{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('./XValues1.npy')\n",
    "Y=np.load('./YValues1.npy')\n",
    "Y=np.squeeze(Y)\n",
    "\n",
    "x_train_raw = X\n",
    "y_train_raw = Y\n",
    "\n",
    "Xtest=np.load('./XValues2.npy')\n",
    "Ytest=np.load('./YValues2.npy')\n",
    "Ytest=np.squeeze(Ytest)\n",
    "\n",
    "x_test_raw = Xtest\n",
    "y_test_raw = Ytest\n",
    "\n",
    "# length check\n",
    "assert(len(x_train_raw) == len(y_train_raw))\n",
    "assert(len(x_test_raw) == len(y_test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3 # 3 labels: 0:normal, 1:MCI, 2:Alzh\n",
    "\n",
    "x_train = np.reshape(x_train_raw,(-1,256,256,170,1))\n",
    "x_test = np.reshape(x_test_raw,(-1,256,256,170,1))\n",
    "\n",
    "# choosing a 16 by 16 by 16 slot in the images\n",
    "x_train = x_train[:, 100:116, 100:116, 100:116, :]\n",
    "x_test = x_test[:, 100:116, 100:116, 100:116, :]\n",
    "\n",
    "# change lables to 1-hot form matrix\n",
    "y_train = to_categorical(y_train_raw, n_classes)\n",
    "y_test = to_categorical(y_test_raw, n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = tf.placeholder(tf.float32, shape=[None, 16, 16, 16, 1])\n",
    "y_input = tf.placeholder(tf.float32, shape=[None, n_classes]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(x_train_data, keep_rate=0.7, seed=None):\n",
    "    \n",
    "    # conv => 16*16*16\n",
    "    conv1 = tf.layers.conv3d(inputs=x_train_data, filters=32, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu)\n",
    "    # conv => 16*16*16\n",
    "    conv2 = tf.layers.conv3d(inputs=conv1, filters=32, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu)\n",
    "    # pool => 8*8*8\n",
    "    pool3 = tf.layers.max_pooling3d(inputs=conv2, pool_size=[2, 2, 2], strides=2)\n",
    "\n",
    "    # conv => 8*8*8\n",
    "    conv4 = tf.layers.conv3d(inputs=pool3, filters=64, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu)\n",
    "    # conv => 8*8*8\n",
    "    conv5 = tf.layers.conv3d(inputs=conv4, filters=64, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu)\n",
    "    # pool => 4*4*4\n",
    "    pool6 = tf.layers.max_pooling3d(inputs=conv5, pool_size=[2, 2, 2], strides=2)\n",
    "\n",
    "    # conv => 4*4*4\n",
    "    conv7 = tf.layers.conv3d(inputs=pool6, filters=128, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu)\n",
    "    # conv => 4*4*4\n",
    "    conv8 = tf.layers.conv3d(inputs=conv7, filters=128, kernel_size=[3,3,3], padding='same', activation=tf.nn.relu)\n",
    "    # pool => 2*2*2\n",
    "    pool9 = tf.layers.max_pooling3d(inputs=conv8, pool_size=[2, 2, 2], strides=2)\n",
    "\n",
    "    cnn3d_bn = tf.layers.batch_normalization(inputs=pool9, training=True)\n",
    "\n",
    "    flattening = tf.reshape(cnn3d_bn, [-1, 2*2*2*128])\n",
    "    dense = tf.layers.dense(inputs=flattening, units=1024, activation=tf.nn.relu)\n",
    "    # (1-keep_rate) is the probability that the node will be kept\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=keep_rate, training=True)\n",
    "\n",
    "    y_conv = tf.layers.dense(inputs=dropout, units=3)\n",
    "    \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(x_train_data, y_train_data, x_test_data, y_test_data, learning_rate=0.05, keep_rate=0.7, epochs=10, batch_size=128):\n",
    "\n",
    "    prediction = cnn_model(x_input, keep_rate, seed = 1)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y_input))\n",
    "\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "           \n",
    "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_input, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    \n",
    "    iterations = int(len(x_train_data)/batch_size) + 1\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        import datetime\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        iterations = int(len(x_train_data)/batch_size) + 1\n",
    "        # run epochs\n",
    "        for epoch in range(epochs):\n",
    "            start_time_epoch = datetime.datetime.now()\n",
    "            print('Epoch', epoch, 'started', end='')\n",
    "            epoch_loss = 0\n",
    "            # mini batch\n",
    "            for itr in range(iterations):\n",
    "                mini_batch_x = x_train_data[itr*batch_size: (itr+1)*batch_size]\n",
    "                mini_batch_y = y_train_data[itr*batch_size: (itr+1)*batch_size]\n",
    "                _optimizer, _cost = sess.run([optimizer, cost], feed_dict={x_input: mini_batch_x, y_input: mini_batch_y})\n",
    "                epoch_loss += _cost\n",
    "\n",
    "            #  using mini batch in case not enough memory\n",
    "            acc = 0\n",
    "            itrs = int(len(x_test_data)/batch_size) + 1\n",
    "            for itr in range(itrs):\n",
    "                mini_batch_x_test = x_test_data[itr*batch_size: (itr+1)*batch_size]\n",
    "                mini_batch_y_test = y_test_data[itr*batch_size: (itr+1)*batch_size]\n",
    "                acc += sess.run(accuracy, feed_dict={x_input: mini_batch_x_test, y_input: mini_batch_y_test})\n",
    "            end_time_epoch = datetime.datetime.now()\n",
    "            print(' Testing Set Accuracy:',acc/itrs, ' Time elapse: ', str(end_time_epoch - start_time_epoch))\n",
    "        end_time = datetime.datetime.now()\n",
    "        print('Time elapse: ', str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started Testing Set Accuracy: 0.166666671634  Time elapse:  0:00:02.447662\n",
      "Epoch 1 started Testing Set Accuracy: 0.333333335817  Time elapse:  0:00:02.408019\n",
      "Epoch 2 started Testing Set Accuracy: 0.333333343267  Time elapse:  0:00:02.446472\n",
      "Epoch 3 started Testing Set Accuracy: 0.416666671634  Time elapse:  0:00:02.519480\n",
      "Epoch 4 started Testing Set Accuracy: 0.333333335817  Time elapse:  0:00:02.557558\n",
      "Epoch 5 started Testing Set Accuracy: 0.500000007451  Time elapse:  0:00:02.424104\n",
      "Epoch 6 started Testing Set Accuracy: 0.166666671634  Time elapse:  0:00:02.542757\n",
      "Epoch 7 started Testing Set Accuracy: 0.250000007451  Time elapse:  0:00:02.480380\n",
      "Epoch 8 started Testing Set Accuracy: 0.500000007451  Time elapse:  0:00:02.425845\n",
      "Epoch 9 started Testing Set Accuracy: 0.0833333358169  Time elapse:  0:00:02.265855\n",
      "Time elapse:  0:00:24.519134\n"
     ]
    }
   ],
   "source": [
    "train_neural_network(x_train, y_train, x_test, y_test, epochs=10, batch_size=3, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
